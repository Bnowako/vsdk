<!DOCTYPE html>
<html>
<head>
  <title>Voice Assistant</title>
  <!-- It's recommended to use the latest stable version of Socket.IO -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.5.1/socket.io.js"></script>
  <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono&display=swap" rel="stylesheet">
  <style>
    :root {
      --primary-color: #4A90E2;
      --secondary-color: #F5F7FA;
      --text-color: #2C3E50;
      --shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }

    body {
      font-family: 'Segoe UI', system-ui, -apple-system, sans-serif;
      background: linear-gradient(135deg, #f5f7fa 0%, #e4e7eb 100%);
      margin: 0;
      padding: 2rem;
      min-height: 100vh;
      display: flex;
      flex-direction: column;
      align-items: center;
    }

    .container {
      width: 90%;
      max-width: 800px;
      margin: 0 auto;
    }

    h1 {
      color: var(--text-color);
      font-size: 2.5rem;
      margin-bottom: 2rem;
      text-align: center;
    }

    .controls {
      display: flex;
      gap: 1rem;
      justify-content: center;
      margin-bottom: 2rem;
    }

    button {
      background-color: var(--primary-color);
      color: white;
      border: none;
      padding: 0.8rem 1.5rem;
      border-radius: 50px;
      cursor: pointer;
      font-size: 1rem;
      font-weight: 500;
      transition: transform 0.2s, box-shadow 0.2s;
      box-shadow: var(--shadow);
    }

    button:hover {
      transform: translateY(-2px);
      box-shadow: 0 6px 8px rgba(0, 0, 0, 0.15);
    }

    button:active {
      transform: translateY(0);
    }

    button.recording {
      background-color: #DC3545;
      animation: pulse 2s infinite;
    }

    @keyframes pulse {
      0% { box-shadow: 0 0 0 0 rgba(220, 53, 69, 0.4); }
      70% { box-shadow: 0 0 0 10px rgba(220, 53, 69, 0); }
      100% { box-shadow: 0 0 0 0 rgba(220, 53, 69, 0); }
    }

    #conversation {
      background: white;
      border-radius: 16px;
      box-shadow: var(--shadow);
      padding: 2rem;
      height: 60vh;
      overflow-y: auto;
      scroll-behavior: smooth;
    }

    #conversation h2 {
      color: var(--text-color);
      margin-top: 0;
      margin-bottom: 1.5rem;
      font-size: 1.5rem;
    }

    .message {
      background: var(--secondary-color);
      padding: 1.5rem;
      border-radius: 12px;
      margin-bottom: 1rem;
      box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
    }

    .message-metrics {
      display: flex;
      gap: 0.5rem;
      flex-wrap: wrap;
      margin-bottom: 0.5rem;
    }

    .message-time {
      font-size: 0.75rem;
      color: #666;
      background-color: #E9ECEF;
      border-radius: 16px;
      padding: 0.25rem 0.75rem;
    }

    .message-content {
      margin-top: 0.5rem;
    }

    .transcript, .response {
      margin: 0.5rem 0;
      line-height: 1.5;
    }

    .transcript strong, .response strong {
      color: var(--primary-color);
    }

    /* Scrollbar styling */
    #conversation::-webkit-scrollbar {
      width: 8px;
    }

    #conversation::-webkit-scrollbar-track {
      background: #f1f1f1;
      border-radius: 4px;
    }

    #conversation::-webkit-scrollbar-thumb {
      background: #888;
      border-radius: 4px;
    }

    #conversation::-webkit-scrollbar-thumb:hover {
      background: #666;
    }

    .metrics-table {
      width: 100%;
      border-collapse: collapse;
      margin-bottom: 1rem;
      background: rgba(74, 144, 226, 0.05);
      border-radius: 8px;
      overflow: hidden;
    }

    .metrics-table th, .metrics-table td {
      padding: 0.5rem 1rem;
      text-align: left;
      border-bottom: 1px solid rgba(74, 144, 226, 0.1);
    }

    .metrics-table th {
      background: rgba(74, 144, 226, 0.1);
      font-weight: 500;
      color: var(--primary-color);
      font-size: 0.85rem;
      text-transform: uppercase;
    }

    .metrics-table td {
      font-family: 'Roboto Mono', monospace;
      font-size: 0.9rem;
    }

    .metrics-table tr:last-child td {
      border-bottom: none;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>Voice Assistant</h1>

    <div class="controls">
      <button id="talkButton" onclick="startStream()">
        Start Talking
      </button>
      <button onclick="startConversation()">Connect</button>
      <button onclick="endConversation()">Disconnect</button>
    </div>

    <div id="conversation">
      <h2>Conversation History</h2>
      <!-- Messages will be appended here -->
    </div>
  </div>

  <script>
    /***** Configuration Constants *****/
    const CONFIG = {
      SOCKET_URL: 'ws://localhost:8000/ws',
      AUDIO_SAMPLE_RATE: 8000,
      SCRIPT_PROCESSOR_BUFFER_SIZE: 256,
      INT16_NEGATIVE_MULTIPLIER: 0x8000, // 32768 for negative values
      INT16_POSITIVE_MULTIPLIER: 0x7FFF, // 32767 for positive values
      BIAS: 0x84,                      // 132
      CLIP: 32635
    };

    /***** Global Variables *****/
    let socket;
    let pendingAudioChunks = [];
    let audioQueue = [];
    let isPlaying = false;
    let audioContext = new (window.AudioContext || window.webkitAudioContext)({
      sampleRate: CONFIG.AUDIO_SAMPLE_RATE
    });

    /***** Form Submission Handler *****/
    document.getElementById('uploadForm').addEventListener('submit', function(event) {
      event.preventDefault(); // Prevent default form submission

      const formData = new FormData(this);
      fetch('/form', {
        method: 'POST',
        body: formData
      })
      .then(response => response.json())
      .then(data => {
        console.log('Form submitted successfully:', data);
      })
      .catch(error => {
        console.error('Error submitting form:', error);
      });
    });

    /***** Utility Functions *****/
    function generateId(length) {
      const characters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789';
      let result = '';
      for (let i = 0; i < length; i++) {
        result += characters.charAt(Math.floor(Math.random() * characters.length));
      }
      return result;
    }

    function float32ToInt16(float32Array) {
      const int16Array = new Int16Array(float32Array.length);
      for (let i = 0; i < float32Array.length; i++) {
        const s = Math.max(-1, Math.min(1, float32Array[i]));
        int16Array[i] = s < 0
          ? s * CONFIG.INT16_NEGATIVE_MULTIPLIER
          : s * CONFIG.INT16_POSITIVE_MULTIPLIER;
      }
      return int16Array;
    }

    function int16ToMuLaw(int16Array) {
      const muLawArray = new Uint8Array(int16Array.length);
      for (let i = 0; i < int16Array.length; i++) {
        muLawArray[i] = linearToMuLawSample(int16Array[i]);
      }
      return muLawArray;
    }

    function linearToMuLawSample(sample) {
      // Clip the sample
      sample = Math.max(-CONFIG.CLIP, Math.min(CONFIG.CLIP, sample));

      // Determine sign and adjust sample if negative
      let sign = (sample < 0) ? 0x80 : 0;
      if (sign !== 0) {
        sample = -sample;
      }

      // Add bias and compute exponent and mantissa
      sample += CONFIG.BIAS;
      const exponent = getExponent(sample);
      const mantissa = (sample >> (exponent + 3)) & 0x0F;
      const muLawByte = ~(sign | (exponent << 4) | mantissa);
      return muLawByte;
    }

    function getExponent(sample) {
      let exponent = 7;
      for (let expMask = 0x4000; (sample & expMask) === 0 && exponent > 0; exponent--, expMask >>= 1);
      return exponent;
    }

    function muLawDecode(muLawByte) {
      muLawByte = ~muLawByte & 0xFF;
      const sign = (muLawByte & 0x80) ? -1 : 1;
      const exponent = (muLawByte & 0x70) >> 4;
      const mantissa = muLawByte & 0x0F;
      const magnitude = ((mantissa << 4) + 8) << exponent;
      return sign * magnitude;
    }

    /***** WebSocket Functions *****/
    function startConversation() {
      socket = new WebSocket(CONFIG.SOCKET_URL);

      socket.onopen = () => {
        // Send StartEvent conforming to the Pydantic model
        const startEvent = {
          event: 'start',
          start: {
            streamSid: generateId(32),
            accountSid: generateId(32),
            callSid: generateId(32)
          }
        };
        socket.send(JSON.stringify(startEvent));
      };

      socket.onmessage = (event) => {
        const data = JSON.parse(event.data);
        switch (data.event) {
          case 'result':
            handleResultEvent(data);
            break;
          case 'media':
            handleMediaEvent(data);
            break;
          case 'mark':
            handleMarkEvent(data);
            break;
          case 'clear':
            handleClearEvent();
            break;
          default:
            console.warn('Unknown event type:', data.event);
        }
      };

      socket.onclose = () => {
        console.log('Disconnected');
      };
    }

    function endConversation() {
      const button = document.getElementById('talkButton');
      button.classList.remove('recording');
      button.textContent = 'Start Talking';
      if (socket) {
        socket.send(JSON.stringify({ event: 'closed' }));
        socket.close();
        console.log('Disconnected');
      }
    }

    /***** Audio Functions *****/
    async function startStream() {
      const button = document.getElementById('talkButton');
      button.classList.add('recording');
      button.textContent = 'Recording...';
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        console.log('Audio stream obtained:', stream);

        // Create a dedicated AudioContext for this stream
        const localAudioContext = new (window.AudioContext || window.webkitAudioContext)({
          sampleRate: CONFIG.AUDIO_SAMPLE_RATE
        });
        console.log('AudioContext sample rate:', localAudioContext.sampleRate);

        const source = localAudioContext.createMediaStreamSource(stream);
        const processor = localAudioContext.createScriptProcessor(
          CONFIG.SCRIPT_PROCESSOR_BUFFER_SIZE, 1, 1
        );

        source.connect(processor);
        processor.connect(localAudioContext.destination);

        processor.onaudioprocess = (e) => {
          const inputBuffer = e.inputBuffer.getChannelData(0);
          const int16Buffer = float32ToInt16(inputBuffer);
          const muLawBuffer = int16ToMuLaw(int16Buffer);
          const base64Buffer = btoa(String.fromCharCode.apply(null, muLawBuffer));

          // Send MediaEvent conforming to the Pydantic model
          const mediaEvent = {
            event: 'media',
            media: { payload: base64Buffer }
          };
          socket.send(JSON.stringify(mediaEvent));
        };
      } catch (err) {
        console.error('Error accessing audio stream:', err);
      }
    }

    function handleMediaEvent(data) {
      const encodedPayload = data.media.payload;
      // Decode base64 to Uint8Array (μ-law encoded bytes)
      const muLawBytes = Uint8Array.from(atob(encodedPayload), c => c.charCodeAt(0));

      // Decode μ-law bytes to PCM samples
      const pcmSamples = new Int16Array(muLawBytes.length);
      for (let i = 0; i < muLawBytes.length; i++) {
        pcmSamples[i] = muLawDecode(muLawBytes[i]);
      }

      // Normalize PCM samples to Float32Array in range [-1, 1]
      const float32Samples = new Float32Array(pcmSamples.length);
      for (let i = 0; i < pcmSamples.length; i++) {
        float32Samples[i] = pcmSamples[i] / 32768;
      }

      // Enqueue audio samples for playback
      audioQueue.push(float32Samples);
      pendingAudioChunks.push({ samples: float32Samples, markId: null });
    }

    function handleMarkEvent(data) {
      console.log("Received mark");
      const markId = data.mark.name;
      // Associate the markId with the first unmarked audio chunk
      const unmarkedChunk = pendingAudioChunks.find(chunk => chunk.markId === null);
      if (unmarkedChunk) {
        unmarkedChunk.markId = markId;
      }
      // Start playing if not already playing
      if (!isPlaying) {
        playNextAudio();
      }
    }

    function playNextAudio() {
      // Find the next chunk with an assigned markId
      const nextChunkIndex = pendingAudioChunks.findIndex(chunk => chunk.markId !== null);
      console.log("Playing next audio", nextChunkIndex);

      if (nextChunkIndex === -1) {
        isPlaying = false;
        return;
      }
      isPlaying = true;
      const chunk = pendingAudioChunks.splice(nextChunkIndex, 1)[0];

      playAudio(chunk.samples, () => {
        sendMarkEventToServer(chunk.markId);
        playNextAudio();
      });
    }

    function playAudio(float32Samples, callback) {
      console.log(`Playing audio chunk - ${float32Samples.length} samples`);
      const buffer = audioContext.createBuffer(1, float32Samples.length, CONFIG.AUDIO_SAMPLE_RATE);
      buffer.copyToChannel(float32Samples, 0);

      const source = audioContext.createBufferSource();
      source.buffer = buffer;
      source.connect(audioContext.destination);
      source.onended = callback;
      source.start(0);
    }

    function sendMarkEventToServer(markId) {
      // Send MarkEvent conforming to the Pydantic model (without extra properties)
      const markEvent = {
        event: 'mark',
        mark: { name: markId }
      };
      socket.send(JSON.stringify(markEvent));
    }

    function stopAudio() {
      // Clear pending audio chunks
      pendingAudioChunks = [];
      if (audioContext && audioContext.state !== 'closed') {
        audioContext.close().then(() => {
          audioContext = new (window.AudioContext || window.webkitAudioContext)({
            sampleRate: CONFIG.AUDIO_SAMPLE_RATE
          });
        });
      }
      isPlaying = false;
      console.log('Audio stopped');
    }

    /***** Incoming Result Event Handler *****/
    function handleResultEvent(data) {
      const result = data.result;
      const messageDiv = document.createElement('div');
      messageDiv.className = 'message';

      // Format timing data
      const timings = [
        { label: 'Speech-to-Text', value: result.stt_duration, unit: 's' },
        { label: 'AI Processing', value: result.llm_duration, unit: 's' },
        { label: 'Text-to-Speech', value: result.tts_duration, unit: 's' },
        { label: 'First Chunk', value: result.first_chunk_time, unit: 's' },
        { label: 'Total Duration', value: result.total_duration, unit: 's' }
      ];

      messageDiv.innerHTML = `
        <table class="metrics-table">
          <thead>
            <tr>
              <th>Metric</th>
              <th>Duration</th>
            </tr>
          </thead>
          <tbody>
            ${timings.map(timing => `
              <tr>
                <td>${timing.label}</td>
                <td>${timing.value.toLocaleString()} ${timing.unit}</td>
              </tr>
            `).join('')}
          </tbody>
        </table>
        <div class="message-content">
          <div class="transcript"><strong>You:</strong> ${result.transcript}</div>
          <div class="response"><strong>Assistant:</strong> ${result.response}</div>
        </div>
      `;

      document.getElementById('conversation').appendChild(messageDiv);
      messageDiv.scrollIntoView({ behavior: 'smooth' });
    }

    function handleClearEvent() {
      sendMarksForRemainingChunks();
      stopAudio();
    }

    function sendMarksForRemainingChunks() {
      pendingAudioChunks.forEach(chunk => {
        if (chunk.markId !== null) {
          sendMarkEventToServer(chunk.markId);
        } else {
          const tempMarkId = generateId(10);
          chunk.markId = tempMarkId;
          sendMarkEventToServer(tempMarkId);
        }
      });
      pendingAudioChunks = [];
    }
  </script>
</body>
</html>
