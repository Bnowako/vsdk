<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
    <title>AI Plugin Assistant</title>
     <style>
      :root {
  --primary-color: #4A90E2;
  --secondary-color: #F5F7FA;
  --text-color: #2C3E50;
  --shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
}

body {
  font-family: 'Segoe UI', system-ui, -apple-system, sans-serif;
  background: linear-gradient(135deg, #f5f7fa 0%, #e4e7eb 100%);
  margin: 0;
  padding: 1rem;
  width: 400px;
  height: 500px;
}

.container {
  width: 100%;
  max-width: 750px;
  height: 100%;
  display: flex;
  flex-direction: column;
  margin: 0 auto;
}

h1 {
  color: var(--text-color);
  font-size: 1.5rem;
  margin-bottom: 1rem;
  text-align: center;
}
body {
    width: 100%;
    height: 100vh;
    margin: 0;
    padding: 10px;
    font-family: Arial, sans-serif;
    display: flex;
    flex-direction: column;
    overflow: hidden;
  }

  #conversation {
    flex: 1;
    overflow-y: auto;
    margin-bottom: 10px;
    padding: 5px;
  }

  .controls {
    display: flex;
    flex-direction: column;
    gap: 8px;
    padding: 10px 0;
  }

  /* Add more of your existing styles here */
.controls {
  display: flex;
  gap: 0.5rem;
  justify-content: center;
  margin-bottom: 1rem;
}

button {
  background-color: var(--primary-color);
  color: white;
  border: none;
  padding: 0.5rem 1rem;
  border-radius: 50px;
  cursor: pointer;
  font-size: 0.9rem;
  font-weight: 500;
  transition: transform 0.2s, box-shadow 0.2s;
  box-shadow: var(--shadow);
}

button:hover {
  transform: translateY(-2px);
  box-shadow: 0 6px 8px rgba(0, 0, 0, 0.15);
}

button:active {
  transform: translateY(0);
}

button.listening {
  background-color: #28a745;
  animation: pulse 2s infinite;
}

@keyframes pulse {
  0% { box-shadow: 0 0 0 0 rgba(40, 167, 69, 0.4); }
  70% { box-shadow: 0 0 0 10px rgba(40, 167, 69, 0); }
  100% { box-shadow: 0 0 0 0 rgba(40, 167, 69, 0); }
}

#conversation {
  background: white;
  border-radius: 10px;
  box-shadow: var(--shadow);
  padding: 1rem;
  flex-grow: 1;
  overflow-y: auto;
  scroll-behavior: smooth;
}

#conversation h2 {
  color: var(--text-color);
  margin-top: 0;
  margin-bottom: 1rem;
  font-size: 1.2rem;
}

.message {
  background: var(--secondary-color);
  padding: 1rem;
  border-radius: 8px;
  margin-bottom: 0.8rem;
  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
}

.metrics-table {
  width: 100%;
  border-collapse: collapse;
  margin-bottom: 0.8rem;
  background: rgba(74, 144, 226, 0.05);
  border-radius: 8px;
  overflow: hidden;
  font-size: 0.8rem;
}

.metrics-table th, .metrics-table td {
  padding: 0.3rem 0.6rem;
  text-align: left;
  border-bottom: 1px solid rgba(74, 144, 226, 0.1);
}

.metrics-table th {
  background: rgba(74, 144, 226, 0.1);
  font-weight: 500;
  color: var(--primary-color);
  font-size: 0.75rem;
  text-transform: uppercase;
}

.metrics-table tr:last-child td {
  border-bottom: none;
}

.message-content {
  margin-top: 0.5rem;
}

.transcript, .response {
  margin: 0.5rem 0;
  line-height: 1.4;
  font-size: 0.9rem;
}

.transcript strong, .response strong {
  color: var(--primary-color);
}

.status-indicator {
  display: inline-flex;
  align-items: center;
  gap: 0.5rem;
  padding: 0.3rem 0.8rem;
  border-radius: 50px;
  background: var(--secondary-color);
  margin-bottom: 0.8rem;
  align-self: center;
}

.status-dot {
  width: 8px;
  height: 8px;
  border-radius: 50%;
  background-color: #ccc;
}

.status-dot.connected {
  background-color: #28a745;
}

.status-dot.disconnected {
  background-color: #dc3545;
}

.status-dot.connecting {
  background-color: #ffc107;
}

    </style>
  </head>

  <body>
    <div class="container">
      <h1>AI Plugin Assistant</h1>

      <div class="status-indicator">
        <div id="wsStatus" class="status-dot disconnected"></div>
        <span id="wsStatusText">Disconnected</span>
      </div>

      <div class="controls">
        <button id="talkButton">Talk to AI Assistant</button>
        <button id="connectButton">Connect</button>
        <button id="disconnectButton">Disconnect</button>
      </div>

      <div id="conversation">
        <h2>Conversation History</h2>
        <div class="message info">
          <div class="message-content">
            <div class="info-message">
              <strong>Getting Started:</strong>
              <ol>
                <li>Click "Connect" to connect to the server</li>
                <li>Click "Talk to AI Assistant" to start speaking</li>
                <li>When prompted, allow microphone access</li>
              </ol>
            </div>
          </div>
        </div>
      </div>
    </div>

    <script>
      /***** Configuration Constants *****/
      const CONFIG = {
        SOCKET_URL: 'ws://localhost:8000/plugin/ws',
        AUDIO_SAMPLE_RATE: 8000,
        SCRIPT_PROCESSOR_BUFFER_SIZE: 256,
        INT16_NEGATIVE_MULTIPLIER: 0x8000,
        INT16_POSITIVE_MULTIPLIER: 0x7FFF,
        BIAS: 0x84,
        CLIP: 32635
      };

      /***** Global Variables *****/
      let socket,
          pendingAudioChunks = [],
          isPlaying = false,
          audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: CONFIG.AUDIO_SAMPLE_RATE });

      /***** Utility Functions *****/
      const generateId = length =>
        Array.from({ length }, () => "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789".charAt(Math.floor(Math.random() * 62))).join('');

      const float32ToInt16 = float32Array =>
        Int16Array.from(float32Array, s => {
          s = Math.max(-1, Math.min(1, s));
          return s < 0 ? s * CONFIG.INT16_NEGATIVE_MULTIPLIER : s * CONFIG.INT16_POSITIVE_MULTIPLIER;
        });

      const int16ToMuLaw = int16Array => Uint8Array.from(int16Array, linearToMuLawSample);

      function linearToMuLawSample(sample) {
        sample = Math.max(-CONFIG.CLIP, Math.min(CONFIG.CLIP, sample));
        let sign = sample < 0 ? 0x80 : 0;
        if (sign) sample = -sample;
        sample += CONFIG.BIAS;
        const exponent = getExponent(sample);
        const mantissa = (sample >> (exponent + 3)) & 0x0F;
        return ~(sign | (exponent << 4) | mantissa);
      }

      function getExponent(sample) {
        let exponent = 7;
        for (let expMask = 0x4000; (sample & expMask) === 0 && exponent > 0; exponent--, expMask >>= 1);
        return exponent;
      }

      const muLawDecode = muLawByte => {
        muLawByte = ~muLawByte & 0xFF;
        const sign = (muLawByte & 0x80) ? -1 : 1;
        const exponent = (muLawByte & 0x70) >> 4;
        const mantissa = muLawByte & 0x0F;
        return sign * (((mantissa << 4) + 8) << exponent);
      };

      /***** WebSocket Functions *****/
      const updateConnectionStatus = (status, text) => {
        document.getElementById('wsStatus').className = `status-dot ${status}`;
        document.getElementById('wsStatusText').textContent = text;
      };

      function startConversation() {
        updateConnectionStatus('connecting', 'Connecting...');
        socket = new WebSocket(CONFIG.SOCKET_URL);
        socket.onopen = () => {
          updateConnectionStatus('connected', 'Connected');
        };
        socket.onmessage = ({ data }) => {
          const msg = JSON.parse(data);
          switch (msg.type) {
            case 'result':     handleResultEvent(msg); break;
            case 'media':      handleMediaEvent(msg); break;
            case 'mark':       handleMarkEvent(msg); break;
            case 'stop_speaking': handleClearEvent(); break;
            case 'start_restream': console.log('Restreaming audio...'); break;
            case 'start_responding': console.log('AI starting to respond...'); break;
            default: console.warn('Unknown event type:', msg.type);
          }
        };
        socket.onclose = () => {
          updateConnectionStatus('disconnected', 'Disconnected');
          console.log('Disconnected');
        };
      }

      function sendAudioData(base64Buffer) {
        if (socket && socket.readyState === WebSocket.OPEN) {
          socket.send(JSON.stringify({
            type: 'media',
            audio: base64Buffer,
            sid: generateId(10)
          }));
        }
      }

      function sendMarkEvent(markId) {
        if (socket && socket.readyState === WebSocket.OPEN) {
          socket.send(JSON.stringify({
            type: 'mark',
            mark_id: markId,
            sid: generateId(10)
          }));
        }
      }

      /***** Audio Functions *****/
      async function startStream() {
        const button = document.getElementById('talkButton');
        button.classList.add('listening');
        button.textContent = 'Requesting mic...';

        try {
          const stream = await navigator.mediaDevices.getUserMedia({
            audio: { echoCancellation: true, noiseSuppression: true, autoGainControl: true }
          });
          button.textContent = 'Listening...';

          const localAudioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: CONFIG.AUDIO_SAMPLE_RATE });
          const source = localAudioContext.createMediaStreamSource(stream);
          const processor = localAudioContext.createScriptProcessor(CONFIG.SCRIPT_PROCESSOR_BUFFER_SIZE, 1, 1);

          source.connect(processor);
          processor.connect(localAudioContext.destination);
          button.dataset.streamActive = "true";

          window.currentAudioStream = stream;
          window.currentAudioProcessor = processor;
          window.currentAudioSource = source;

          processor.onaudioprocess = e => {
            if (button.dataset.streamActive !== "true") return;
            const inputBuffer = e.inputBuffer.getChannelData(0);
            const muLawBuffer = int16ToMuLaw(float32ToInt16(inputBuffer));
            const base64Buffer = btoa(String.fromCharCode(...muLawBuffer));
            sendAudioData(base64Buffer);
          };
        } catch (err) {
          console.error('Error accessing audio stream:', err);
          button.classList.remove('listening');
          button.textContent = 'Talk to AI Assistant';
          const errorDiv = document.createElement('div');
          errorDiv.className = 'message error';
          errorDiv.innerHTML = `
            <div class="message-content">
              <div class="error-message"><strong>Error:</strong> ${err.message || 'Microphone access denied'}</div>
              <div class="error-help">Please click the camera icon in the browser address bar and allow microphone access.</div>
            </div>`;
          document.getElementById('conversation').appendChild(errorDiv);
          errorDiv.scrollIntoView({ behavior: 'smooth' });
        }
      }

      function handleMediaEvent({ audio }) {
        const muLawBytes = Uint8Array.from(atob(audio), c => c.charCodeAt(0));
        const pcmSamples = Int16Array.from(muLawBytes, muLawDecode);
        const float32Samples = Float32Array.from(pcmSamples, s => s / 32768);
        pendingAudioChunks.push({ samples: float32Samples, markId: null });
        if (!isPlaying) playNextAudio();
      }

      function handleMarkEvent({ mark_id }) {
        const unmarked = pendingAudioChunks.find(chunk => chunk.markId === null);
        if (unmarked) unmarked.markId = mark_id;
        if (!isPlaying) playNextAudio();
      }

      function playNextAudio() {
        if (pendingAudioChunks.length === 0) {
          isPlaying = false;
          return;
        }

        const nextIndex = pendingAudioChunks.findIndex(chunk => chunk.markId !== null);
        if (nextIndex === -1) {
          isPlaying = false;
          return;
        }

        isPlaying = true;
        const { samples, markId } = pendingAudioChunks.splice(nextIndex, 1)[0];

        try {
          playAudio(samples, () => {
            sendMarkEvent(markId);
            playNextAudio();
          });
        } catch (err) {
          console.error('Error playing audio:', err);
          playNextAudio(); // Try to continue with next chunk
        }
      }

      function playAudio(samples, callback) {
        // Resume audioContext if it's suspended
        if (audioContext.state === 'suspended') {
          audioContext.resume();
        }

        const buffer = audioContext.createBuffer(1, samples.length, CONFIG.AUDIO_SAMPLE_RATE);
        buffer.copyToChannel(samples, 0);
        const source = audioContext.createBufferSource();
        source.buffer = buffer;
        source.connect(audioContext.destination);
        source.onended = callback;
        source.start(0);
      }

      function stopAudio() {
        pendingAudioChunks = [];
        if (audioContext && audioContext.state !== 'closed') {
          audioContext.close().then(() => {
            audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: CONFIG.AUDIO_SAMPLE_RATE });
          }).catch(err => console.error('Error closing audio context:', err));
        }
        isPlaying = false;
      }

      function endConversation() {
        const button = document.getElementById('talkButton');
        button.classList.remove('listening');
        button.textContent = 'Talk to AI Assistant';
        button.dataset.streamActive = "false";

        updateConnectionStatus('disconnected', 'Disconnected');

        if (window.currentAudioStream) {
          window.currentAudioStream.getTracks().forEach(track => track.stop());
          window.currentAudioStream = null;
        }
        if (window.currentAudioSource) {
          window.currentAudioSource.disconnect();
          window.currentAudioSource = null;
        }
        if (window.currentAudioProcessor) {
          window.currentAudioProcessor.disconnect();
          window.currentAudioProcessor = null;
        }
        if (socket) {
          socket.close();
        }
      }

      function sendMarksForRemainingChunks() {
        pendingAudioChunks.forEach(chunk => {
          const markId = chunk.markId || generateId(10);
          chunk.markId = markId;
          sendMarkEvent(markId);
        });
        pendingAudioChunks = [];
      }

      function toggleTalking() {
        const button = document.getElementById('talkButton');
        if (button.classList.contains('listening')) {
          endConversation();
        } else {
          if (!socket || socket.readyState !== WebSocket.OPEN) startConversation();
          button.classList.add('listening');
          button.textContent = 'Listening...';
          startStream();
        }
      }

      /***** Result and Event Handlers *****/
      function handleResultEvent({ result }) {
        const stt = result.stt_result;
        const llm = result.llm_result;
        const tts = result.tts_result;

        // Calculate durations
        const sttDuration = stt.stt_end_time - stt.stt_start_time;
        const llmDuration = llm.end_time - llm.start_time;
        const ttsDuration = tts.end_time - tts.start_time;
        const totalDuration = ttsDuration + llmDuration + sttDuration;
        const firstTTSChunk = tts.first_chunk_time - tts.start_time;

        const timings = [
          { label: 'Speech-to-Text', value: sttDuration.toFixed(2), unit: 's' },
          { label: 'LLM', value: llmDuration.toFixed(2), unit: 's' },
          { label: 'Text-to-Speech', value: ttsDuration.toFixed(2), unit: 's' },
          { label: 'First Chunk', value: firstTTSChunk.toFixed(2), unit: 's' },
          { label: 'Total Duration', value: totalDuration.toFixed(2), unit: 's' }
        ];

        const messageDiv = document.createElement('div');
        messageDiv.className = 'message';
        messageDiv.innerHTML = `
          <table class="metrics-table">
            <thead><tr><th>Metric</th><th>Duration</th></tr></thead>
            <tbody>${timings.map(t => `<tr><td>${t.label}</td><td>${t.value} ${t.unit}</td></tr>`).join('')}</tbody>
          </table>
          <div class="message-content">
            <div class="transcript"><strong>You:</strong> ${stt.transcript}</div>
            <div class="response"><strong>Assistant:</strong> ${llm.response}</div>
          </div>`;
        document.getElementById('conversation').appendChild(messageDiv);
        messageDiv.scrollIntoView({ behavior: 'smooth' });
      }

      function handleClearEvent() {
        sendMarksForRemainingChunks();
        stopAudio();
      }

      /***** Initialize *****/
      document.addEventListener('DOMContentLoaded', () => {
        const talkButton = document.getElementById('talkButton');
        document.getElementById('connectButton').addEventListener('click', startConversation);
        document.getElementById('disconnectButton').addEventListener('click', endConversation);
        talkButton.addEventListener('click', toggleTalking);
        // Auto-connect on page load
        startConversation();
      });
    </script>
  </body>
</html>
